## Selection Sort (الشرح الوافي)

### التعريف السريع

الـ **Selection Sort** هي خوارزمية ترتيب بتعتمد على فكرة "الاختيار الذكي". بنقسم المصفوفة لجزئين: جزء مترتب (بيكبر تدريجياً) وجزء لسه متبهدل. في كل خطوة، بننقي "أصغر" عنصر من الجزء المتبهدل ونحطه في مكانه الصح في الجزء المترتب. هي خوارزمية **In-place** (مبتستهلكش ميموري زيادة) و **Comparison-based** (بتعتمد على المقارنة).

---

### الشرح التفصيلي

بص يا هندسة، الـ Selection Sort دي عاملة زي واحد واقف قدام طابور طويل من الناس وعايز يرتبهم من الأقصر للأطول. هو مش هيقعد يبدل كل اتنين جنب بعض زي الـ Bubble Sort (لأن ده وجع دماغ وتضييع وقت في الحركة). هو بيعمل إيه؟

بيتمشى من أول الطابور لآخره "بعينه" بس، ويدور على أقصر واحد في الطابور كله. أول ما يلاقيه، يروح جايبه من إيده ومبدله مع الشخص اللي واقف في أول مكان. كده أول مكان "اتحجز" لأقصر واحد فعلاً. بعدين يكرر نفس الحركة على باقي الناس (من تاني واحد لآخر الطابور) وهكذا.

#### المستوى السطحي (إيه ده؟)

هي خوارزمية بسيطة جداً هدفها تقليل عدد عمليات الـ **Swap** (التبديل). بدل ما بنبدل كتير، إحنا بندور الأول وبعدين نبدل مرة واحدة بس في كل لفة.

#### المستوى المتوسط (إزاي بيشتغل؟)

الخوارزمية بتعتمد على **Two Nested Loops**:

- **الـ Outer Loop:** دي اللي بتحدد المكان اللي بنرتب فيه دلوقتي (يعني هنحط الرقم الصغير فين؟ في الـ Index 0 ولا 1 ولا 2..).
    
- **الـ Inner Loop:** دي "الكشاف" اللي بيلف على الجزء غير المترتب عشان يطلع لنا الـ **Minimum**.
    
- **الـ Swap:** بيحصل مرة واحدة بس في نهاية كل لفة من الـ Outer Loop.
    

#### المستوى العميق (ليه اتصمم كده؟ والـ Trade-offs)

هنا بقى الكلام اللي بيفرق مهندس الـ ITI الشاطر:

- **الـ Time Complexity:** الخوارزمية دي "عنيدة" جداً. الـ Complexity بتاعتها دايماً $O(N^2)$ في كل الحالات (Best, Average, Worst). ليه؟ لأنها معندهاش ذكاء الـ Bubble Sort إنها تكتشف إن الـ Array مترتبة. هي لازم تلف وتدور على الـ Minimum في كل مرة "عشان تتأكد".
    
- **الـ Memory Writes (الزتونة):** الميزة الكبرى والوحيدة للـ Selection Sort هي إنها بتعمل $O(N)$ عمليات Swap فقط. في حين إن الـ Bubble Sort والـ Insertion Sort ممكن يعملوا $O(N^2)$ عمليات تبديل.
    
    - **ليه ده مهم؟** في أنظمة الـ **Embedded Systems** أو لما بتكتب على **Flash Memory** (زي الـ SSD أو الـ SD Cards)، عمليات الـ Write بتقلل عمر الميموري الافتراضي وبتاخد طاقة (Battery) أكتر. فالـ Selection Sort هنا بتبقى بطلة لأنها "بتحافظ" على الميموري من كتر الـ Writing.
        
- **الـ Stability:** الخوارزمية دي **Unstable**. يعني لو عندك "أحمد" و "أحمد" تاني، ترتيبهم النسبي ممكن يتغير بعد الترتيب بسبب الـ Swaps البعيدة.
    

---

#### كيفية العمل (How It Works) - خطوة بخطوة

تخيل الـ Array دي: `[64, 25, 12, 22, 11]` وطولها $N=5$.

1. **اللغة الأولى (i = 0):**
    
    - نفترض إن الـ `min_index` هو 0 (يعني رقم 64).
        
    - نلف بـ `j` من 1 لـ 4.
        
    - هل 25 أصغر من 64؟ أيوة -> `min_index = 1`.
        
    - هل 12 أصغر من 25؟ أيوة -> `min_index = 2`.
        
    - هل 22 أصغر من 12؟ لأ.
        
    - هل 11 أصغر من 12؟ أيوة -> `min_index = 4`.
        
    - **نهاية اللفة:** بدل `arr[0]` مع `arr[4]`.
        
    - النتيجة: `[11, 25, 12, 22, 64]`. (الـ 11 في مكانها الصح للأبد).
        
2. **اللفة الثانية (i = 1):**
    
    - نفترض الـ `min_index` هو 1 (رقم 25).
        
    - ندور في `[12, 22, 64]`.. نلاقي الـ 12 هي الأصغر (`min_index = 2`).
        
    - **نهاية اللفة:** بدل `arr[1]` مع `arr[2]`.
        
    - النتيجة: `[11, 12, 25, 22, 64]`.
        
3. **اللفة الثالثة (i = 2):**
    
    - نفترض الـ `min_index` هو 2 (رقم 25).
        
    - ندور في `[22, 64]`.. نلاقي الـ 22 هي الأصغر (`min_index = 3`).
        
    - **نهاية اللفة:** بدل `arr[2]` مع `arr[3]`.
        
    - النتيجة: `[11, 12, 22, 25, 64]`.
        
4. **اللفة الرابعة (i = 3):**
    
    - هنقارن 25 بـ 64، الـ 25 أصغر، الـ `min_index` هيفضل 3.
        
    - مفيش تبديل حقيقي (أو هنبدل الـ 25 مع نفسها).
        
    - النتيجة النهائية: `[11, 12, 22, 25, 64]`.
        

---

#### الأمثلة العملية (C++ Implementation)

ده كود كامل، Runnable، ومعاه شرح لكل سطر بالبلدي:

C++

```
#include <iostream>
#include <vector>
#include <algorithm> // عشان خاطر swap

using namespace std;

/**
 * دالة الـ Selection Sort
 * التكلفة الزمنية: O(N^2) في كل الحالات
 * التكلفة المكانية: O(1) لأن الترتيب في نفس المكان
 */
void selectionSort(vector<int>& arr) {
    int n = arr.size();

    // اللوب الخارجية: بتمشي على أماكن المصفوفة واحد واحد عشان تحط فيه الرقم الصح
    for (int i = 0; i < n - 1; i++) {
        
        // بنفترض مبدئياً إن العنصر اللي واقف في المكان الحالي هو أصغر واحد
        int min_idx = i;

        // اللوب الداخلية: بتبدأ من بعد المكان الحالي لحد آخر المصفوفة
        // وظيفتها: "تفتش" على أي رقم يكون أصغر من اللي معانا
        for (int j = i + 1; j < n; j++) {
            if (arr[j] < arr[min_idx]) {
                // لو لقينا واحد أصغر، بنسجل العنوان (index) بتاعه فوراً
                min_idx = j;
            }
        }

        // بعد ما اللوب الداخلية تخلص تفتيش، بنشوف لو لقينا فعلاً رقم أصغر
        // بنعمل عملية التبديل (Swap) مرة واحدة بس في كل لفة خارجية
        if (min_idx != i) {
            swap(arr[i], arr[min_idx]);
            // ملاحظة: عدد الـ Swaps هنا هو O(N) وده سر قوة الخوارزمية دي
        }
    }
}

// دالة بسيطة لطباعة المصفوفة
void printArray(const vector<int>& arr) {
    for (int val : arr) {
        cout << val << " ";
    }
    cout << endl;
}

int main() {
    // مصفوفة تجريبية
    vector<int> data = {29, 10, 14, 37, 13};
    
    cout << "Array before sorting: ";
    printArray(data);

    selectionSort(data);

    cout << "Array after sorting:  ";
    printArray(data);

    return 0;
}

/*
الـ Output المتوقع:
Array before sorting: 29 10 14 37 13 
Array after sorting:  10 13 14 29 37 
*/
```

---

#### الـ Edge Cases والتفاصيل الدقيقة

1. **Already Sorted Array:** لو دخلت لها مصفوفة `[1, 2, 3, 4, 5]`، الـ Selection Sort للاسف هتفضل تلف وتدور وتعمل المقارنات كاملة ( $N^2$ مقارنة) وكأنها متعرفش إنها مترتبة. ده عكس الـ Bubble و الـ Insertion.
    
2. **Reverse Sorted Array:** نفس الأداء $O(N^2)$.
    
3. **Stability Issue:** تخيل عندك `[5(a), 8, 5(b), 2]`.
    
    - الـ Min هو 2. هتبدله مع 5(a).
        
    - الـ Array هتبقى `[2, 8, 5(b), 5(a)]`.
        
    - لاحظ إن 5(a) بقت بعد 5(b). عشان كدة بنقول عليها **Unstable**.
        

---

### الربط بالمفاهيم التانية

الموضوع ده مرتبط بـ:

- **Memory Optimization:** في الأنظمة اللي الـ Writing فيها مكلف.
    
- **Heap Sort:** دي تعتبر النسخة "الوحش" من الـ Selection Sort. بدل ما بتدور على الـ Min في $O(N)$ باستخدام Loop، بتستخدم Data Structure اسمها **Heap** عشان تجيبه في $O(\log N)$، فبتخلي الترتيب كله $O(N \log N)$.
    
- **Searching:** لأن جوهر الـ Selection Sort هو عملية Linear Search متكررة.
    

---

### المصادر والقراءة الإضافية

- **كتاب Introduction to Algorithms (CLRS):** الجزء الخاص بالـ Comparison Sorts.
    
- **GeeksForGeeks:** شرح مفصل لمقارنة عدد الـ Swaps بين الخوارزميات.
    
- **VisuAlgo.net:** بيوريك الـ `min_index` وهو بيتحرك.
    

---

### Mermaid Visualization (تطبيقاً للوصايا السبع)

Code snippet

```
graph TD
    %% 1. البداية
    Start(("بداية اللفة i")) 
    
    %% 2. العمليات مع علامات التنصيص للعربي
    InitMin["افترض إن min_index = i"]
    InnerLoop{"هل j < n؟"}
    Compare{"هل Arr[j] < Arr[min_index]؟"}
    UpdateMin["تحديث min_index = j"]
    
    %% 3. التوصيلات
    Start --> InitMin
    InitMin --> InnerLoop
    
    InnerLoop -- "نعم" --> Compare
    Compare -- "نعم" --> UpdateMin
    UpdateMin --> NextJ["j++"]
    Compare -- "لا" --> NextJ
    NextJ --> InnerLoop
    
    %% 4. نهاية اللفة والتبديل
    InnerLoop -- "لا (خلصنا تفتيش)" --> CheckSwap{"هل min_index != i؟"}
    CheckSwap -- "نعم" --> PerformSwap["Swap(Arr[i], Arr[min_index])"]
    CheckSwap -- "لا" --> End(("نهاية اللفة"))
    PerformSwap --> End

    %% 5. الستايل
    style InnerLoop fill:#ff9,stroke:#333
    style Compare fill:#ff9,stroke:#333
    style PerformSwap fill:#bbf,stroke:#333
    style Start fill:#dfd,stroke:#333
```

كده يا باشمهندس الـ Selection Sort بقى في جيبك الصغير بكل تفاصيله. نخش على الـ **Insertion Sort** بنفس الاستفاضة؟ ولا فيه حتة لسه محتاجة "نحت"؟